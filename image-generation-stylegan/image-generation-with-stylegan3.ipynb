{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.4.0+cu121)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.19.0+cu121)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (6.0.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.3)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.66.4)\n",
      "Collecting click\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting imageio\n",
      "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting imageio-ffmpeg\n",
      "  Downloading imageio_ffmpeg-0.6.0-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting ninja\n",
      "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting opensimplex\n",
      "  Downloading opensimplex-0.4.5.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.1.105)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (10.2.0)\n",
      "Collecting absl-py>=0.4 (from tensorboard)\n",
      "  Downloading absl_py-2.3.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard)\n",
      "  Downloading grpcio-1.73.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard)\n",
      "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.1)\n",
      "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard)\n",
      "  Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard) (59.6.0)\n",
      "Requirement already satisfied: six>1.9 in /usr/lib/python3/dist-packages (from tensorboard) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch) (1.3.0)\n",
      "Downloading scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m136.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Downloading imageio_ffmpeg-0.6.0-py3-none-manylinux2014_x86_64.whl (29.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.5/29.5 MB\u001b[0m \u001b[31m165.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
      "Downloading opensimplex-0.4.5.1-py3-none-any.whl (267 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.3.0-py3-none-any.whl (135 kB)\n",
      "Downloading grpcio-1.73.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m153.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m159.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Installing collected packages: werkzeug, tensorboard-data-server, scipy, protobuf, opensimplex, ninja, markdown, imageio-ffmpeg, imageio, grpcio, click, absl-py, tensorboard\n",
      "Successfully installed absl-py-2.3.0 click-8.2.1 grpcio-1.73.0 imageio-2.37.0 imageio-ffmpeg-0.6.0 markdown-3.8 ninja-1.11.1.4 opensimplex-0.4.5.1 protobuf-6.31.1 scipy-1.15.3 tensorboard-2.19.0 tensorboard-data-server-0.7.2 werkzeug-3.1.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision psutil numpy scipy tqdm click imageio imageio-ffmpeg ninja opensimplex tensorboard --no-cache-dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'stylegan3'...\n",
      "remote: Enumerating objects: 212, done.\u001b[K\n",
      "remote: Counting objects: 100% (163/163), done.\u001b[K\n",
      "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
      "remote: Total 212 (delta 99), reused 90 (delta 90), pack-reused 49 (from 1)\u001b[K\n",
      "Receiving objects: 100% (212/212), 4.16 MiB | 9.75 MiB/s, done.\n",
      "Resolving deltas: 100% (108/108), done.\n",
      "/workspace/stylegan3/stylegan3\n",
      "Usage: train.py [OPTIONS]\n",
      "\n",
      "  Train a GAN using the techniques described in the paper \"Alias-Free\n",
      "  Generative Adversarial Networks\".\n",
      "\n",
      "  Examples:\n",
      "\n",
      "  # Train StyleGAN3-T for AFHQv2 using 8 GPUs.\n",
      "  python train.py --outdir=~/training-runs --cfg=stylegan3-t --data=~/datasets/afhqv2-512x512.zip \\\n",
      "      --gpus=8 --batch=32 --gamma=8.2 --mirror=1\n",
      "\n",
      "  # Fine-tune StyleGAN3-R for MetFaces-U using 1 GPU, starting from the pre-trained FFHQ-U pickle.\n",
      "  python train.py --outdir=~/training-runs --cfg=stylegan3-r --data=~/datasets/metfacesu-1024x1024.zip \\\n",
      "      --gpus=8 --batch=32 --gamma=6.6 --mirror=1 --kimg=5000 --snap=5 \\\n",
      "      --resume=https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-ffhqu-1024x1024.pkl\n",
      "\n",
      "  # Train StyleGAN2 for FFHQ at 1024x1024 resolution using 8 GPUs.\n",
      "  python train.py --outdir=~/training-runs --cfg=stylegan2 --data=~/datasets/ffhq-1024x1024.zip \\\n",
      "      --gpus=8 --batch=32 --gamma=10 --mirror=1 --aug=noaug\n",
      "\n",
      "Options:\n",
      "  --outdir DIR                    Where to save the results  [required]\n",
      "  --cfg [stylegan3-t|stylegan3-r|stylegan2]\n",
      "                                  Base configuration  [required]\n",
      "  --data [ZIP|DIR]                Training data  [required]\n",
      "  --gpus INT                      Number of GPUs to use  [x>=1; required]\n",
      "  --batch INT                     Total batch size  [x>=1; required]\n",
      "  --gamma FLOAT                   R1 regularization weight  [x>=0; required]\n",
      "  --cond BOOL                     Train conditional model  [default: False]\n",
      "  --mirror BOOL                   Enable dataset x-flips  [default: False]\n",
      "  --aug [noaug|ada|fixed]         Augmentation mode  [default: ada]\n",
      "  --resume [PATH|URL]             Resume from given network pickle\n",
      "  --freezed INT                   Freeze first layers of D  [default: 0; x>=0]\n",
      "  --p FLOAT                       Probability for --aug=fixed  [default: 0.2;\n",
      "                                  0<=x<=1]\n",
      "  --target FLOAT                  Target value for --aug=ada  [default: 0.6;\n",
      "                                  0<=x<=1]\n",
      "  --batch-gpu INT                 Limit batch size per GPU  [x>=1]\n",
      "  --cbase INT                     Capacity multiplier  [default: 32768; x>=1]\n",
      "  --cmax INT                      Max. feature maps  [default: 512; x>=1]\n",
      "  --glr FLOAT                     G learning rate  [default: varies]  [x>=0]\n",
      "  --dlr FLOAT                     D learning rate  [default: 0.002; x>=0]\n",
      "  --map-depth INT                 Mapping network depth  [default: varies]\n",
      "                                  [x>=1]\n",
      "  --mbstd-group INT               Minibatch std group size  [default: 4; x>=1]\n",
      "  --desc STR                      String to include in result dir name\n",
      "  --metrics [NAME|A,B,C|none]     Quality metrics  [default: fid50k_full]\n",
      "  --kimg KIMG                     Total training duration  [default: 25000;\n",
      "                                  x>=1]\n",
      "  --tick KIMG                     How often to print progress  [default: 4;\n",
      "                                  x>=1]\n",
      "  --snap TICKS                    How often to save snapshots  [default: 50;\n",
      "                                  x>=1]\n",
      "  --seed INT                      Random seed  [default: 0; x>=0]\n",
      "  --fp32 BOOL                     Disable mixed-precision  [default: False]\n",
      "  --nobench BOOL                  Disable cuDNN benchmarking  [default: False]\n",
      "  --workers INT                   DataLoader worker processes  [default: 3;\n",
      "                                  x>=1]\n",
      "  -n, --dry-run                   Print training options and exit\n",
      "  --help                          Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NVlabs/stylegan3.git\n",
    "%cd stylegan3\n",
    "!python train.py --help\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resizing images: 100%|██████████| 29843/29843 [06:27<00:00, 76.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Gotowe! ZIP zapisany jako: /workspace/cat_dataset_64.zip\n",
      "🧹 Wyczyszczono katalogi tymczasowe.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "base_dir = \"/workspace\"\n",
    "\n",
    "zip_path = os.path.join(base_dir, \"cat_dataset.zip\")\n",
    "unzipped_dir = os.path.join(base_dir, \"cat_dataset_raw\")\n",
    "processed_dir = os.path.join(base_dir, \"cat_dataset_64\")\n",
    "output_zip = os.path.join(base_dir, \"cat_dataset_64.zip\")\n",
    "\n",
    "if os.path.exists(unzipped_dir):\n",
    "    shutil.rmtree(unzipped_dir)\n",
    "os.makedirs(unzipped_dir)\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(unzipped_dir)\n",
    "\n",
    "if os.path.exists(processed_dir):\n",
    "    shutil.rmtree(processed_dir)\n",
    "os.makedirs(processed_dir)\n",
    "\n",
    "image_paths = []\n",
    "for root, _, files in os.walk(unzipped_dir):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_paths.append(os.path.join(root, file))\n",
    "\n",
    "for path in tqdm(image_paths, desc=\"Resizing images\"):\n",
    "    try:\n",
    "        filename = os.path.basename(path)\n",
    "        output_path = os.path.join(processed_dir, filename)\n",
    "\n",
    "        with Image.open(path) as img:\n",
    "            img = img.convert(\"RGB\")\n",
    "            img = img.resize((64, 64))\n",
    "            img.save(output_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {path}: {e}\")\n",
    "\n",
    "with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for root, _, files in os.walk(processed_dir):\n",
    "        for file in files:\n",
    "            full_path = os.path.join(root, file)\n",
    "            arcname = os.path.relpath(full_path, processed_dir)\n",
    "            zipf.write(full_path, arcname)\n",
    "\n",
    "\n",
    "shutil.rmtree(unzipped_dir, ignore_errors=True)\n",
    "shutil.rmtree(processed_dir, ignore_errors=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_kwargs\": {\n",
      "    \"class_name\": \"training.networks_stylegan3.Generator\",\n",
      "    \"z_dim\": 512,\n",
      "    \"w_dim\": 512,\n",
      "    \"mapping_kwargs\": {\n",
      "      \"num_layers\": 2\n",
      "    },\n",
      "    \"channel_base\": 65536,\n",
      "    \"channel_max\": 1024,\n",
      "    \"magnitude_ema_beta\": 0.9955736831881946,\n",
      "    \"conv_kernel\": 1,\n",
      "    \"use_radial_filters\": true\n",
      "  },\n",
      "  \"D_kwargs\": {\n",
      "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
      "    \"block_kwargs\": {\n",
      "      \"freeze_layers\": 0\n",
      "    },\n",
      "    \"mapping_kwargs\": {},\n",
      "    \"epilogue_kwargs\": {\n",
      "      \"mbstd_group_size\": 4\n",
      "    },\n",
      "    \"channel_base\": 32768,\n",
      "    \"channel_max\": 512\n",
      "  },\n",
      "  \"G_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08,\n",
      "    \"lr\": 0.0025\n",
      "  },\n",
      "  \"D_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08,\n",
      "    \"lr\": 0.002\n",
      "  },\n",
      "  \"loss_kwargs\": {\n",
      "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
      "    \"r1_gamma\": 5.0,\n",
      "    \"blur_init_sigma\": 0,\n",
      "    \"blur_fade_kimg\": 800.0\n",
      "  },\n",
      "  \"data_loader_kwargs\": {\n",
      "    \"pin_memory\": true,\n",
      "    \"prefetch_factor\": 2,\n",
      "    \"num_workers\": 3\n",
      "  },\n",
      "  \"training_set_kwargs\": {\n",
      "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
      "    \"path\": \"cat_dataset_64.zip\",\n",
      "    \"use_labels\": false,\n",
      "    \"max_size\": 29843,\n",
      "    \"xflip\": true,\n",
      "    \"resolution\": 64,\n",
      "    \"random_seed\": 0\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"batch_size\": 128,\n",
      "  \"batch_gpu\": 128,\n",
      "  \"metrics\": [\n",
      "    \"fid50k_full\"\n",
      "  ],\n",
      "  \"total_kimg\": 250,\n",
      "  \"kimg_per_tick\": 10,\n",
      "  \"image_snapshot_ticks\": 5,\n",
      "  \"network_snapshot_ticks\": 5,\n",
      "  \"random_seed\": 0,\n",
      "  \"ema_kimg\": 40.0,\n",
      "  \"augment_kwargs\": {\n",
      "    \"class_name\": \"training.augment.AugmentPipe\",\n",
      "    \"xflip\": 1,\n",
      "    \"rotate90\": 1,\n",
      "    \"xint\": 1,\n",
      "    \"scale\": 1,\n",
      "    \"rotate\": 1,\n",
      "    \"aniso\": 1,\n",
      "    \"xfrac\": 1,\n",
      "    \"brightness\": 1,\n",
      "    \"contrast\": 1,\n",
      "    \"lumaflip\": 1,\n",
      "    \"hue\": 1,\n",
      "    \"saturation\": 1\n",
      "  },\n",
      "  \"ada_target\": 0.6,\n",
      "  \"resume_pkl\": \"/workspace/training-runs/00005-stylegan3-r-cat_dataset_64-gpus1-batch128-gamma5/network-snapshot-000250.pkl\",\n",
      "  \"ada_kimg\": 100,\n",
      "  \"ema_rampup\": null,\n",
      "  \"run_dir\": \"training-runs/00006-stylegan3-r-cat_dataset_64-gpus1-batch128-gamma5\"\n",
      "}\n",
      "\n",
      "Output directory:    training-runs/00006-stylegan3-r-cat_dataset_64-gpus1-batch128-gamma5\n",
      "Number of GPUs:      1\n",
      "Batch size:          128 images\n",
      "Training duration:   250 kimg\n",
      "Dataset path:        cat_dataset_64.zip\n",
      "Dataset size:        29843 images\n",
      "Dataset resolution:  64\n",
      "Dataset labels:      False\n",
      "Dataset x-flips:     True\n",
      "\n",
      "Creating output directory...\n",
      "Launching processes...\n",
      "Loading training set...\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/sampler.py:65: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
      "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n",
      "\n",
      "Num images:  59686\n",
      "Image shape: [3, 64, 64]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Resuming from \"/workspace/training-runs/00005-stylegan3-r-cat_dataset_64-gpus1-batch128-gamma5/network-snapshot-000250.pkl\"\n",
      "/usr/local/lib/python3.11/dist-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Done.\n",
      "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Done.\n",
      "\n",
      "Generator                     Parameters  Buffers  Output shape         Datatype\n",
      "---                           ---         ---      ---                  ---     \n",
      "mapping.fc0                   262656      -        [128, 512]           float32 \n",
      "mapping.fc1                   262656      -        [128, 512]           float32 \n",
      "mapping                       -           512      [128, 16, 512]       float32 \n",
      "synthesis.input.affine        2052        -        [128, 4]             float32 \n",
      "synthesis.input               1048576     3081     [128, 1024, 36, 36]  float32 \n",
      "synthesis.L0_36_1024.affine   525312      -        [128, 1024]          float32 \n",
      "synthesis.L0_36_1024          1049600     157      [128, 1024, 36, 36]  float16 \n",
      "synthesis.L1_36_1024.affine   525312      -        [128, 1024]          float32 \n",
      "synthesis.L1_36_1024          1049600     157      [128, 1024, 36, 36]  float16 \n",
      "synthesis.L2_36_1024.affine   525312      -        [128, 1024]          float32 \n",
      "synthesis.L2_36_1024          1049600     157      [128, 1024, 36, 36]  float16 \n",
      "synthesis.L3_36_1024.affine   525312      -        [128, 1024]          float32 \n",
      "synthesis.L3_36_1024          1049600     157      [128, 1024, 36, 36]  float16 \n",
      "synthesis.L4_52_1024.affine   525312      -        [128, 1024]          float32 \n",
      "synthesis.L4_52_1024          1049600     169      [128, 1024, 52, 52]  float16 \n",
      "synthesis.L5_52_1024.affine   525312      -        [128, 1024]          float32 \n",
      "synthesis.L5_52_1024          1049600     157      [128, 1024, 52, 52]  float16 \n",
      "synthesis.L6_52_1024.affine   525312      -        [128, 1024]          float32 \n",
      "synthesis.L6_52_1024          1049600     157      [128, 1024, 52, 52]  float16 \n",
      "synthesis.L7_52_1024.affine   525312      -        [128, 1024]          float32 \n",
      "synthesis.L7_52_1024          1049600     157      [128, 1024, 52, 52]  float16 \n",
      "synthesis.L8_84_1024.affine   525312      -        [128, 1024]          float32 \n",
      "synthesis.L8_84_1024          1049600     169      [128, 1024, 84, 84]  float16 \n",
      "synthesis.L9_84_1024.affine   525312      -        [128, 1024]          float32 \n",
      "synthesis.L9_84_1024          1049600     157      [128, 1024, 84, 84]  float16 \n",
      "synthesis.L10_84_1024.affine  525312      -        [128, 1024]          float32 \n",
      "synthesis.L10_84_1024         1049600     157      [128, 1024, 84, 84]  float16 \n",
      "synthesis.L11_84_1024.affine  525312      -        [128, 1024]          float32 \n",
      "synthesis.L11_84_1024         1049600     157      [128, 1024, 84, 84]  float16 \n",
      "synthesis.L12_84_1024.affine  525312      -        [128, 1024]          float32 \n",
      "synthesis.L12_84_1024         1049600     25       [128, 1024, 84, 84]  float16 \n",
      "synthesis.L13_64_1024.affine  525312      -        [128, 1024]          float32 \n",
      "synthesis.L13_64_1024         1049600     25       [128, 1024, 64, 64]  float16 \n",
      "synthesis.L14_64_3.affine     525312      -        [128, 1024]          float32 \n",
      "synthesis.L14_64_3            3075        1        [128, 3, 64, 64]     float16 \n",
      "synthesis                     -           -        [128, 3, 64, 64]     float32 \n",
      "---                           ---         ---      ---                  ---     \n",
      "Total                         24153095    5552     -                    -       \n",
      "\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Done.\n",
      "\n",
      "Discriminator  Parameters  Buffers  Output shape        Datatype\n",
      "---            ---         ---      ---                 ---     \n",
      "b64.fromrgb    2048        16       [128, 512, 64, 64]  float16 \n",
      "b64.skip       262144      16       [128, 512, 32, 32]  float16 \n",
      "b64.conv0      2359808     16       [128, 512, 64, 64]  float16 \n",
      "b64.conv1      2359808     16       [128, 512, 32, 32]  float16 \n",
      "b64            -           16       [128, 512, 32, 32]  float16 \n",
      "b32.skip       262144      16       [128, 512, 16, 16]  float16 \n",
      "b32.conv0      2359808     16       [128, 512, 32, 32]  float16 \n",
      "b32.conv1      2359808     16       [128, 512, 16, 16]  float16 \n",
      "b32            -           16       [128, 512, 16, 16]  float16 \n",
      "b16.skip       262144      16       [128, 512, 8, 8]    float16 \n",
      "b16.conv0      2359808     16       [128, 512, 16, 16]  float16 \n",
      "b16.conv1      2359808     16       [128, 512, 8, 8]    float16 \n",
      "b16            -           16       [128, 512, 8, 8]    float16 \n",
      "b8.skip        262144      16       [128, 512, 4, 4]    float16 \n",
      "b8.conv0       2359808     16       [128, 512, 8, 8]    float16 \n",
      "b8.conv1       2359808     16       [128, 512, 4, 4]    float16 \n",
      "b8             -           16       [128, 512, 4, 4]    float16 \n",
      "b4.mbstd       -           -        [128, 513, 4, 4]    float32 \n",
      "b4.conv        2364416     16       [128, 512, 4, 4]    float32 \n",
      "b4.fc          4194816     -        [128, 512]          float32 \n",
      "b4.out         513         -        [128, 1]            float32 \n",
      "---            ---         ---      ---                 ---     \n",
      "Total          26488833    288      -                   -       \n",
      "\n",
      "Setting up augmentation...\n",
      "Distributing across 1 GPUs...\n",
      "Setting up training phases...\n",
      "Exporting sample images...\n",
      "Initializing logs...\n",
      "Training for 250 kimg...\n",
      "\n",
      "tick 0     kimg 0.1      time 24s          sec/tick 7.3     sec/kimg 57.33   maintenance 16.8   cpumem 2.20   gpumem 46.02  reserved 48.30  augment 0.000\n",
      "Evaluating metrics...\n",
      "/usr/local/lib/python3.11/dist-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "{\"results\": {\"fid50k_full\": 229.6927904597123}, \"metric\": \"fid50k_full\", \"total_time\": 323.93093085289, \"total_time_str\": \"5m 24s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1749485629.4556596}\n",
      "tick 1     kimg 10.2     time 8m 54s       sec/tick 179.0   sec/kimg 17.71   maintenance 330.7  cpumem 2.68   gpumem 38.92  reserved 49.34  augment 0.000\n",
      "tick 2     kimg 20.4     time 11m 53s      sec/tick 179.1   sec/kimg 17.71   maintenance 0.2    cpumem 2.68   gpumem 38.92  reserved 49.34  augment 0.000\n",
      "tick 3     kimg 30.5     time 14m 53s      sec/tick 179.1   sec/kimg 17.71   maintenance 0.2    cpumem 2.68   gpumem 38.92  reserved 49.34  augment 0.000\n",
      "tick 4     kimg 40.6     time 17m 52s      sec/tick 179.1   sec/kimg 17.71   maintenance 0.7    cpumem 2.68   gpumem 38.92  reserved 49.34  augment 0.000\n",
      "tick 5     kimg 50.7     time 20m 52s      sec/tick 179.2   sec/kimg 17.72   maintenance 0.2    cpumem 2.68   gpumem 38.94  reserved 49.34  augment 0.000\n",
      "Evaluating metrics...\n",
      "{\"results\": {\"fid50k_full\": 155.61480567131719}, \"metric\": \"fid50k_full\", \"total_time\": 322.361759185791, \"total_time_str\": \"5m 22s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000050.pkl\", \"timestamp\": 1749486856.5825946}\n",
      "tick 6     kimg 60.8     time 29m 21s      sec/tick 179.1   sec/kimg 17.71   maintenance 330.3  cpumem 2.71   gpumem 38.95  reserved 49.34  augment 0.000\n",
      "tick 7     kimg 70.9     time 32m 21s      sec/tick 179.1   sec/kimg 17.71   maintenance 0.4    cpumem 2.71   gpumem 38.92  reserved 49.34  augment 0.000\n",
      "tick 8     kimg 81.0     time 35m 20s      sec/tick 179.0   sec/kimg 17.70   maintenance 0.2    cpumem 2.71   gpumem 38.92  reserved 49.34  augment 0.000\n",
      "tick 9     kimg 91.1     time 38m 19s      sec/tick 179.1   sec/kimg 17.72   maintenance 0.2    cpumem 2.71   gpumem 38.92  reserved 49.34  augment 0.000\n",
      "tick 10    kimg 101.2    time 41m 19s      sec/tick 179.0   sec/kimg 17.71   maintenance 0.3    cpumem 2.71   gpumem 38.92  reserved 49.34  augment 0.000\n",
      "Evaluating metrics...\n",
      "{\"results\": {\"fid50k_full\": 144.05119295816115}, \"metric\": \"fid50k_full\", \"total_time\": 321.5625014305115, \"total_time_str\": \"5m 22s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000101.pkl\", \"timestamp\": 1749488081.9768279}\n",
      "tick 11    kimg 111.4    time 49m 47s      sec/tick 179.1   sec/kimg 17.71   maintenance 329.0  cpumem 2.71   gpumem 38.94  reserved 49.34  augment 0.000\n",
      "tick 12    kimg 121.5    time 52m 46s      sec/tick 179.0   sec/kimg 17.71   maintenance 0.2    cpumem 2.71   gpumem 38.94  reserved 49.34  augment 0.000\n",
      "tick 13    kimg 131.6    time 55m 45s      sec/tick 179.1   sec/kimg 17.71   maintenance 0.2    cpumem 2.71   gpumem 38.92  reserved 49.34  augment 0.000\n",
      "tick 14    kimg 141.7    time 58m 45s      sec/tick 179.0   sec/kimg 17.71   maintenance 0.5    cpumem 2.71   gpumem 38.92  reserved 49.34  augment 0.000\n",
      "tick 15    kimg 151.8    time 1h 01m 44s   sec/tick 179.0   sec/kimg 17.70   maintenance 0.2    cpumem 2.71   gpumem 38.94  reserved 49.34  augment 0.000\n",
      "Evaluating metrics...\n",
      "{\"results\": {\"fid50k_full\": 150.93384393343246}, \"metric\": \"fid50k_full\", \"total_time\": 321.0342903137207, \"total_time_str\": \"5m 21s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000151.pkl\", \"timestamp\": 1749489306.2614017}\n",
      "tick 16    kimg 161.9    time 1h 10m 11s   sec/tick 179.0   sec/kimg 17.70   maintenance 327.8  cpumem 2.77   gpumem 38.95  reserved 49.34  augment 0.000\n",
      "tick 17    kimg 172.0    time 1h 13m 10s   sec/tick 178.9   sec/kimg 17.69   maintenance 0.3    cpumem 2.77   gpumem 38.94  reserved 49.34  augment 0.000\n",
      "tick 18    kimg 182.1    time 1h 16m 09s   sec/tick 179.1   sec/kimg 17.71   maintenance 0.1    cpumem 2.77   gpumem 38.92  reserved 49.34  augment 0.000\n",
      "tick 19    kimg 192.3    time 1h 19m 08s   sec/tick 179.0   sec/kimg 17.70   maintenance 0.2    cpumem 2.77   gpumem 38.92  reserved 49.34  augment 0.000\n",
      "tick 20    kimg 202.4    time 1h 22m 07s   sec/tick 179.0   sec/kimg 17.70   maintenance 0.2    cpumem 2.77   gpumem 38.92  reserved 49.34  augment 0.000\n",
      "Evaluating metrics...\n",
      "{\"results\": {\"fid50k_full\": 139.05488534713038}, \"metric\": \"fid50k_full\", \"total_time\": 320.7936372756958, \"total_time_str\": \"5m 21s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000202.pkl\", \"timestamp\": 1749490529.3586745}\n",
      "tick 21    kimg 212.5    time 1h 30m 34s   sec/tick 179.2   sec/kimg 17.72   maintenance 327.6  cpumem 2.71   gpumem 38.94  reserved 49.34  augment 0.000\n",
      "tick 22    kimg 222.6    time 1h 33m 33s   sec/tick 179.0   sec/kimg 17.71   maintenance 0.1    cpumem 2.71   gpumem 38.94  reserved 49.34  augment 0.000\n",
      "tick 23    kimg 232.7    time 1h 36m 33s   sec/tick 179.0   sec/kimg 17.70   maintenance 0.2    cpumem 2.71   gpumem 38.92  reserved 49.34  augment 0.000\n",
      "tick 24    kimg 242.8    time 1h 39m 32s   sec/tick 179.1   sec/kimg 17.71   maintenance 0.2    cpumem 2.71   gpumem 38.92  reserved 49.34  augment 0.000\n",
      "tick 25    kimg 250.1    time 1h 41m 41s   sec/tick 129.3   sec/kimg 17.72   maintenance 0.2    cpumem 2.71   gpumem 38.92  reserved 49.34  augment 0.000\n",
      "Evaluating metrics...\n",
      "{\"results\": {\"fid50k_full\": 158.48777841075486}, \"metric\": \"fid50k_full\", \"total_time\": 321.3035087585449, \"total_time_str\": \"5m 21s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000250.pkl\", \"timestamp\": 1749491703.7650568}\n",
      "\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "!python stylegan3/train.py \\\n",
    "  --outdir=training-runs \\\n",
    "  --cfg=stylegan3-r \\\n",
    "  --data=cat_dataset_64.zip \\\n",
    "  --gpus=1 \\\n",
    "  --batch=128 \\\n",
    "  --gamma=5.0 \\\n",
    "  --mirror=1 \\\n",
    "  --kimg=250 \\\n",
    "  --tick=10 \\\n",
    "  --snap=5 \\\n",
    "  --resume=/workspace/training-runs/00005-stylegan3-r-cat_dataset_64-gpus1-batch128-gamma5/network-snapshot-000250.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file '/workspace/stylegan3/metrics.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python stylegan3/metrics.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network from \"/workspace/training-runs/00002-stylegan3-r-cat_dataset_64-gpus1-batch128-gamma5/network-snapshot-000250.pkl\"...\n",
      "/usr/local/lib/python3.11/dist-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/usr/local/lib/python3.11/dist-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "Dataset options:\n",
      "{\n",
      "  \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
      "  \"path\": \"cat_dataset_64.zip\",\n",
      "  \"resolution\": 64,\n",
      "  \"use_labels\": false\n",
      "}\n",
      "Launching processes...\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Done.\n",
      "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Done.\n",
      "\n",
      "Generator                     Parameters  Buffers  Output shape       Datatype\n",
      "---                           ---         ---      ---                ---     \n",
      "mapping.fc0                   262656      -        [1, 512]           float32 \n",
      "mapping.fc1                   262656      -        [1, 512]           float32 \n",
      "mapping                       -           512      [1, 16, 512]       float32 \n",
      "synthesis.input.affine        2052        -        [1, 4]             float32 \n",
      "synthesis.input               1048576     3081     [1, 1024, 36, 36]  float32 \n",
      "synthesis.L0_36_1024.affine   525312      -        [1, 1024]          float32 \n",
      "synthesis.L0_36_1024          1049600     157      [1, 1024, 36, 36]  float16 \n",
      "synthesis.L1_36_1024.affine   525312      -        [1, 1024]          float32 \n",
      "synthesis.L1_36_1024          1049600     157      [1, 1024, 36, 36]  float16 \n",
      "synthesis.L2_36_1024.affine   525312      -        [1, 1024]          float32 \n",
      "synthesis.L2_36_1024          1049600     157      [1, 1024, 36, 36]  float16 \n",
      "synthesis.L3_36_1024.affine   525312      -        [1, 1024]          float32 \n",
      "synthesis.L3_36_1024          1049600     157      [1, 1024, 36, 36]  float16 \n",
      "synthesis.L4_52_1024.affine   525312      -        [1, 1024]          float32 \n",
      "synthesis.L4_52_1024          1049600     169      [1, 1024, 52, 52]  float16 \n",
      "synthesis.L5_52_1024.affine   525312      -        [1, 1024]          float32 \n",
      "synthesis.L5_52_1024          1049600     157      [1, 1024, 52, 52]  float16 \n",
      "synthesis.L6_52_1024.affine   525312      -        [1, 1024]          float32 \n",
      "synthesis.L6_52_1024          1049600     157      [1, 1024, 52, 52]  float16 \n",
      "synthesis.L7_52_1024.affine   525312      -        [1, 1024]          float32 \n",
      "synthesis.L7_52_1024          1049600     157      [1, 1024, 52, 52]  float16 \n",
      "synthesis.L8_84_1024.affine   525312      -        [1, 1024]          float32 \n",
      "synthesis.L8_84_1024          1049600     169      [1, 1024, 84, 84]  float16 \n",
      "synthesis.L9_84_1024.affine   525312      -        [1, 1024]          float32 \n",
      "synthesis.L9_84_1024          1049600     157      [1, 1024, 84, 84]  float16 \n",
      "synthesis.L10_84_1024.affine  525312      -        [1, 1024]          float32 \n",
      "synthesis.L10_84_1024         1049600     157      [1, 1024, 84, 84]  float16 \n",
      "synthesis.L11_84_1024.affine  525312      -        [1, 1024]          float32 \n",
      "synthesis.L11_84_1024         1049600     157      [1, 1024, 84, 84]  float16 \n",
      "synthesis.L12_84_1024.affine  525312      -        [1, 1024]          float32 \n",
      "synthesis.L12_84_1024         1049600     25       [1, 1024, 84, 84]  float16 \n",
      "synthesis.L13_64_1024.affine  525312      -        [1, 1024]          float32 \n",
      "synthesis.L13_64_1024         1049600     25       [1, 1024, 64, 64]  float16 \n",
      "synthesis.L14_64_3.affine     525312      -        [1, 1024]          float32 \n",
      "synthesis.L14_64_3            3075        1        [1, 3, 64, 64]     float16 \n",
      "synthesis                     -           -        [1, 3, 64, 64]     float32 \n",
      "---                           ---         ---      ---                ---     \n",
      "Total                         24153095    5552     -                  -       \n",
      "\n",
      "Calculating pr50k3...\n",
      "/usr/local/lib/python3.11/dist-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "generator features  items 1024    time 6s           ms/item 5.80\n",
      "generator features  items 2048    time 11s          ms/item 5.08\n",
      "generator features  items 3072    time 16s          ms/item 5.08\n",
      "generator features  items 4096    time 22s          ms/item 5.07\n",
      "generator features  items 5120    time 27s          ms/item 5.07\n",
      "generator features  items 6144    time 32s          ms/item 5.08\n",
      "generator features  items 7168    time 37s          ms/item 5.07\n",
      "generator features  items 8192    time 42s          ms/item 5.07\n",
      "generator features  items 9216    time 48s          ms/item 5.08\n",
      "generator features  items 10240   time 53s          ms/item 5.07\n",
      "generator features  items 11264   time 58s          ms/item 5.07\n",
      "generator features  items 12288   time 1m 03s       ms/item 5.07\n",
      "generator features  items 13312   time 1m 08s       ms/item 5.07\n",
      "generator features  items 14336   time 1m 13s       ms/item 5.07\n",
      "generator features  items 15360   time 1m 19s       ms/item 5.07\n",
      "generator features  items 16384   time 1m 24s       ms/item 5.07\n",
      "generator features  items 17408   time 1m 29s       ms/item 5.10\n",
      "generator features  items 18432   time 1m 34s       ms/item 5.07\n",
      "generator features  items 19456   time 1m 39s       ms/item 5.07\n",
      "generator features  items 20480   time 1m 45s       ms/item 5.08\n",
      "generator features  items 21504   time 1m 50s       ms/item 5.08\n",
      "generator features  items 22528   time 1m 55s       ms/item 5.07\n",
      "generator features  items 23552   time 2m 00s       ms/item 5.07\n",
      "generator features  items 24576   time 2m 05s       ms/item 5.08\n",
      "generator features  items 25600   time 2m 11s       ms/item 5.08\n",
      "generator features  items 26624   time 2m 16s       ms/item 5.06\n",
      "generator features  items 27648   time 2m 21s       ms/item 5.07\n",
      "generator features  items 28672   time 2m 26s       ms/item 5.08\n",
      "generator features  items 29696   time 2m 31s       ms/item 5.07\n",
      "generator features  items 30720   time 2m 37s       ms/item 5.07\n",
      "generator features  items 31744   time 2m 42s       ms/item 5.08\n",
      "generator features  items 32768   time 2m 47s       ms/item 5.08\n",
      "generator features  items 33792   time 2m 52s       ms/item 5.07\n",
      "generator features  items 34816   time 2m 57s       ms/item 5.06\n",
      "generator features  items 35840   time 3m 03s       ms/item 5.07\n",
      "generator features  items 36864   time 3m 08s       ms/item 5.06\n",
      "generator features  items 37888   time 3m 13s       ms/item 5.07\n",
      "generator features  items 38912   time 3m 18s       ms/item 5.06\n",
      "generator features  items 39936   time 3m 23s       ms/item 5.06\n",
      "generator features  items 40960   time 3m 29s       ms/item 5.07\n",
      "generator features  items 41984   time 3m 34s       ms/item 5.07\n",
      "generator features  items 43008   time 3m 39s       ms/item 5.07\n",
      "generator features  items 44032   time 3m 44s       ms/item 5.06\n",
      "generator features  items 45056   time 3m 49s       ms/item 5.06\n",
      "generator features  items 46080   time 3m 54s       ms/item 5.07\n",
      "generator features  items 47104   time 4m 00s       ms/item 5.06\n",
      "generator features  items 48128   time 4m 05s       ms/item 5.08\n",
      "generator features  items 49152   time 4m 10s       ms/item 5.07\n",
      "generator features  items 50000   time 4m 15s       ms/item 5.36\n",
      "{\"results\": {\"pr50k3_precision\": 0.9997599720954895, \"pr50k3_recall\": 0.0}, \"metric\": \"pr50k3\", \"total_time\": 274.31328773498535, \"total_time_str\": \"4m 34s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000250.pkl\", \"timestamp\": 1749508256.4722486}\n",
      "\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "!python stylegan3/calc_metrics.py \\\n",
    "  --gpus=1 \\\n",
    "  --data=cat_dataset_64.zip \\\n",
    "  --metrics=pr50k3 \\\n",
    "  --network=/workspace/training-runs/00002-stylegan3-r-cat_dataset_64-gpus1-batch128-gamma5/network-snapshot-000250.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import legacy  # from StyleGAN3 repo\n",
    "import dnnlib\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "network_pkl = '/workspace/training-runs/00006-stylegan3-r-cat_dataset_64-gpus1-batch128-gamma5/network-snapshot-000250.pkl'\n",
    "with dnnlib.util.open_url(network_pkl) as f:\n",
    "    G = legacy.load_network_pkl(f)['G_ema'].to(device)\n",
    "\n",
    "z1 = torch.randn([1, G.z_dim], device=device)\n",
    "z2 = torch.randn([1, G.z_dim], device=device)\n",
    "\n",
    "w1 = G.mapping(z1, None)\n",
    "w2 = G.mapping(z2, None)\n",
    "\n",
    "img1 = G.synthesis(w1, noise_mode='const')\n",
    "img2 = G.synthesis(w2, noise_mode='const')\n",
    "\n",
    "def interpolate(w1, w2, steps):\n",
    "    return [w1 * (1 - t) + w2 * t for t in np.linspace(0, 1, steps)]\n",
    "\n",
    "interpolated_ws = interpolate(w1, w2, 10)\n",
    "\n",
    "images = [G.synthesis(w, noise_mode='const') for w in interpolated_ws]\n",
    "images = torch.cat(images, dim=0)  # [10, C, H, W]\n",
    "\n",
    "save_image(images, 'interpolation_grid.png', nrow=10, normalize=True, value_range=(-1, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5076601,
     "sourceId": 8505344,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
